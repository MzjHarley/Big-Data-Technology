|Author|Date|
|---|---|
|MZJ|3/7,2022|

>HDFS，全称为"Hadoop Distributed File System",是一种通过网络实现文件在多台主机上进行分布式存储的文件系统，主要针对大规模数据的存储而设计的，用于处理大规模文件，如TB级  
>采用"客户机/服务器"模式，客户端以特定的通信协议通过网络与服务端建立连接，提出文件访问请求，客户端和服务器可以设置访问权限来限制请求方对底层数据存储块的访问。
## 计算机集群结构

分布式文件系统**将文件分布存储到多个计算机节点，成千上万个计算机节点构成计算机集群。**  
**目前分布式文件系统采用的计算机集群为普通硬件**。这就大大降低了硬件上的开销。  
集群中的计算机节点放在机架上，机架上可以存放8 ~ 64个节点，**同一机架的不同计算机节点之间通过网络互连，不同机架之间采用交换机或另一级网络互联**。  

![contents](https://github.com/MzjHarley/Big-Data-Technology/blob/main/img/2.png)

## 分布式文件系统的结构
分布式文件系统将文件分成若干个块进行存储，块是数据读写的基本单元，HDFS默认一个块的大小为64MB.  
与普通文件系统不同，在分布式文件系统中，如果一个文件小于一个数据块的大小，它并不占用整个数据块的存储空间。  
分布式文件系统的物理结构上由计算机集群中的多个节点构成。节点分为两类。
|节点类型|作用|
|---|---|
|主节点|也叫名称节点，负责文件和目录的创建，删除和重命名等，同时管理着数据节点和文件块的映射关系|
|从节点|也叫数据节点，负责存储和读取数据，据名称节点的命令创建，删除和复制数据块|

![contents](https://github.com/MzjHarley/Big-Data-Technology/blob/main/img/3.png)

>客户端只有通过**访问名称节点才能找到请求的文件块所在位置，进而到相应位置读取所需文件块。**  
>在存储时，由名称节点分配存储位置，然后由客户端把数据写入响应数据节点。  
>在读取时，客户端从名称节点获得数据节点和文件块的映射关系，到相应位置访问文件块。  
>由于计算机集群上的节点可能发生故障，为保证数据的完整性，分布式文件系统通常采用多副本存储。  
>文件块会被复制成多个副本，存储在不同的节点上，而不同副本的各个节点会分布在不同的机架上。  
>这样在单个节点出现故障时，可以快速调用副本重启单个节点上的计算过程，而不用重启整个计算过程。整个机架出现故障时不会丢失所有文件块。
## 分布式文件系统的设计需求
|设计需求|具体含义|HDFS实现情况|
|----|----|----|
|透明性|  包括访问透明性、位置透明性、性能和伸缩透明性；访问透明性：用户不需要专门区分哪些是本地文件，哪些是远程文件。用户能够通过相同的操作来访问本地和远程文件资源；位置透明性：不改变路径名的前提下，不管文件副本数量和实际存储位置发生何种变化，对用户而言都可以通过相同的路径名访问同一个文件；性能和伸缩透明性：系统中节点的增加和减少以及性能的变化对用户而言是透明的，用户感觉不到什么时候节点加入或退出| HDFS 只能提供一定程度的访问透明性，完全的位置透明性、性能和伸缩透明性|
|并发控制|客户端对文件的写入不应影响到其他客户端对同一文件的写入|任何时间只允许一个程序写入某个文件|
|文件复制|一个文件可在不同位置拥有多个副本|多副本机制|
|硬件和操作系统异构性|可在不同的计算机和OS上实现同样的客户端和服务端程序|采用java语言开发|
|可伸缩性|支持文件的动态加入或退出|建立在大规模廉价机器上的分布式文件系统集群具有很好的伸缩性|
|容错|保证文件服务在服务端或用户端出现问题时能正常使用|多副本机制，故障自动检测和自动恢复机制|
|安全|保障系统安全性|安全性较弱|
## HDFS特点
硬件出错在普通服务器集群中是一种常态并非异常，因此HDFS在设计上采取了多种机制保证硬件出错的情况下数据的完整性。
|特点|机制|
|---|---|
|兼容廉价的硬件设备|快速检测硬件故障和进行自我恢复的机制|
|流式数据读写|HDFS是为了满足批量数据处理的要求而设计的，因此为了提高数据的吞吐率，放松了POSIX（可移植操作系统接口标准）的要求，从而以流式方式访问文件系统数据，即通过API打开文件的某个数据块后，能够顺序读取；或者通过API向HDFS写入数据。我觉得可以这样理解，就是通过java流式读取或写入。|
|大数据集|HDFS文件通常可以达到GB甚至TB级别|
|简单的文件模型|一次写入，多次读取，文件一旦完成写入，关闭后无法在写入，只能被读取|
|强大的跨平台兼容性|采用java实现|
|不适合低延迟数据访问|HDFS主要针对大规模数据批量处理而设计的，采用流式数据读取，具有很高的数据吞吐率，也意味着较高的延迟|
|无法高效存储大量小文件|小文件是指文件大小小于一个块的文件|
|不支持多用户写入及任意修改文件|HFDS只允许一个文件有一个写入者，不允许多个用户对同一文件执行写操作，而且只允许追加，不可执行随机写操作|
### 为什么HDFS无法高效存储大量小文件？
+ HDFS采用名称节点管理文件系统的元数据，这些元数据被保存在内存中，从而使客户端可以快速获取文件实际存储位置。  
  如果存储大量的小文件，那么名称节点就要消耗很多的内存来保留小文件的元数据，这样元数据检索的效率就会降低，需要花费很多时间找到一个文件的存储位置。  
  如果再继续扩展到十数亿个小文件，名称节点保存元数据所需要的内存空间就会大大增加，以现有硬件水平，无法在内存中保留如此大量的元数据。  
+ 用MapReduce处理大量小文件时，会产生很多的Map任务，进程管理开销大大增加。  
+ 访问小文件的速度要远远高于访问大文件的速度，因为访问大量小文件需要不断从一个节点跳到另一个节点，严重影响性能。  
  
